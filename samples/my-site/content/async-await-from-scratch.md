---
title: Mon site
layout: default
machin: hopddddffdd
---
# Writing async await from scratch in C# with Stephen Toub

Disclaimer : cet article est une repompe totale de l'excellente vid√©o [Writing async/await from scratch in C# with Stephen Toub](https://www.youtube.com/watch?v=R-z2Hv-7nxk) √† destination des francophones sous forme d'un exercice de r√©sum√© et de retranscription.

Async/await est un pattern qui existe en .NET depuis 12 ans environ (2010).

Ce pattern a chang√© la mani√®re dont les d√©veloppeurs interagissent avec le code asynchrone et g√®rent la concurrence.
C'est aussi l'un des plus dangereux, dans le sens o√π il permet facilement de se tirer une balle dans le pied (sans m√™me s'en apercevoir).

Durant ce (long) article nous allons recr√©er le pattern await/async de z√©ro en c# pour comprendre comment il fonctionne.

Comme le dit Stephen en introduction de sa vid√©o, une chose que j'appr√©cie particuli√®rement en tant que d√©veloppeur c'est lorsque j'arrive √† avoir un mod√®le mental de la mani√®re dont fonctionne les choses. Ne pas avoir forc√©ment besoin de tout comprendre dans le d√©tail, chaque ligne de code de quelque chose dont vous vous servez. Mais plus vous en savez sur le fonctionnement interne, mieux vous √™tes capable de vous en servir et d'en tirer le maximum.

Et c'est donc le cas pour le pattern async/await. Il existe depuis de nombreuses ann√©es et on est d√©sormais habitu√©s √† l'utiliser. Mais en r√©alit√© tr√®s peu savent r√©ellement comment il fonctionne r√©ellement et les raisons des nuances et contraintes qu'il impose sur notre mani√®re de coder.

Attachez vos ceintures, c'est parti : nous nous t√©l√©portons plus de 10 ans dans le pass√©, et nous allons impl√©menter de z√©ro le pattern async/await (dans une version simplifi√©).

Nous ne ferons pas attention aux performances.

## asynchronisme et concurrence

Le premier concept fondamental √† aborder lorsque l'on parle d'asynchronisme est la **concurrence**&nbsp;: vous d√©marrez une t√¢che qui peut se terminer imm√©diatement ou bien plus tard mais vous ne le savez pas. Vous l'avez simplement d√©marr√©e puis votre code continue d'effectuer d'autres traitements.

Pendant ce temps la t√¢che que vous avez d√©marr√©e s'ex√©cute et lance m√™me peut-√™tre d'autres traitements. Vous vous retrouvez avec plusieurs traitements qui s'ex√©cutent en m√™me temps.

√Ä la base de ce fonctionnement vous avez le *thread pool*, charg√© de faire s'ex√©cuter chacune de ces t√¢ches.
Donc l'une des premi√®res t√¢ches que nous allons devoir r√©aliser va consister √† recr√©er un thread pool en .NET.

Prenons l'exemple suivant :

```csharp
for (int i = 0; i < 100; i++)
{
    // üëá cette ligne demande au thread pool de mettre en file d'attente un traitement
    ThreadPool.QueueUserWorkItem(delegate { /* traitement s'ex√©cutant en fond */ });
    // üëá et imm√©diatement apr√©s, je peux effectuer un autre traitement
}

Console.ReadLine();
```

Dans cet exemple j'ai un traitement (mon delegate) qui s'ex√©cute de mani√®re asynchrone : je l'ai lanc√© puis j'ai continu√© mon traitement.
Cela ne signifie pas pour autant que le traitement s'ex√©cutera en **concurrence** avec mon code actuel.

Par exemple, dans du code WinForms, si vous lancez ce traitement sur le thread graphique (le thread principal de l'UI) via un appel de `Control.BeginInvoke`, le traitement sera remis en file d'attente sur le thread graphique. Vous aurez bien lanc√© un traitement asynchrone, mais il ne s'ex√©cutera pas en concurrence avec votre code actuel : il s'ex√©cutera **apr√®s** par le **m√™me** thread. 

La concurrence se produira lorsque le code qui s'ex√©cute dans votre delegate s'ex√©cute en m√™me temps (dans un autre thread), que le code qui se situe apr√®s l'instruction `QueueUserWorkItem`. Vous ne ma√Ætrisez pas non plus cette concurrence : elle d√©pendra de votre mat√©riel (nombre de processeurs), de la charge de travail, de milliers d'autres param√®tres que vous ne ma√Ætrisez pas.

```csharp
public void Button1_Click(object sender, EventArgs e)
{
    for (int i = 0; i < 100; i++)
    {
        var value = i;
        ThreadPool.QueueUserWorkItem(delegate {            
            // üëá demande au thread principal (UI) d'effectuer ce traitement
            Control.BeginInvoke(this, new MethodInvoker(delegate { Console.WriteLine(value); }, null));
        });
    }
}
```

Donc vous ne pouvez pas avoir de concurrence sans asynchronisme, alors que vous pouvez avoir de l'asynchronisme sans concurrence.

```csharp
for (int i = 0; i < 100; i++)
{
    var value = i;
    ThreadPool.QueueUserWorkItem(delegate {
        Console.WriteLine(value);
        Thread.Sleep(1000);
    });
}
Console.ReadLine();
```

En √©crivant ce code sur une machine disposant par exemple de 8 processeurs logiques, donc avec supposons 8 threads pouvant s'ex√©cuter en parall√©le, nous voyons s'afficher les nombres de 0 √† 7 tr√®s vite en ordre al√©atoire, puis de 8 √† 15, etc.

## Port√©e et capture de variable

Retour sur un point qui peut sembler √©vident : l'importance de stocker la valeur de `i` dans une variable locale.
Si nous modifions le code pour revenir √† une version d'apparence plus simple, o√π nous utilisons directement `i` dans l'appel de `Console.WriteLine()` :

```csharp
for (int i = 0; i < 100; i++)
{
    //var value = i; üëà on ne capture plus la variable i
    ThreadPool.QueueUserWorkItem(delegate {
        Console.WriteLine(i);
        Thread.Sleep(1000);
    });
}
Console.ReadLine();
```

Voici le r√©sultat affich√© :

![](async-await-from-scratch-01.gif)

Uniquement le nombre 100, sur 100 lignes.

Car en r√©alit√© ce code ne fait r√©ellement que mettre en file d'attente 1000 traitements d'affichage de la valeur de `i`.
Et le temps que ces traitements se lan√ßent r√©ellement, la variable `i` a √©t√© incr√©ment√©e pour valoir 100.

Ce type d'erreur vient d'un probl√®me de m√©connaissance li√© aux closures (port√©es). En effet, lorsque l'on √©crit un `delegate`, qui se r√©f√®re √† une variable d√©clar√©e en dehors de la port√©e, c'est une **r√©f√©rence** vers cette variable qui est utilis√©e : tous les traitements se r√©f√®rent donc √† la m√™me variable qui est incr√©ment√©e au fur et √† mesure.

C'est ce que le compilateur fait par d√©faut pour que le comportement soit le plus logique, surtout lorsque des variables de type r√©f√©rences (classes) sont utilis√©es : on s'attend √† manipuler l'objet de la port√©e parente, et non une "copie".

Pour obtenir une copie de la variable d√©di√©e au traitement avec la valeur au moment pr√©cis o√π la t√¢che a √©t√© programmer, il faut donc passer par une variable interm√©diaire, comme dans notre premier exemple :

```csharp
for (int i = 0; i < 100; i++)
{
    int capturedVariable = i; // üëà cr√©ation d'une variable locale pour capturer la valeur courante de i
    ThreadPool.QueueUserWorkItem(delegate {
        Console.WriteLine(capturedVariable);
        Thread.Sleep(1000);
    })
}
Console.ReadLine();
```

Nous aurons bien le r√©sultat attendu qui s'affiche, √† savoir tous les nombres s'incr√©mentant de 0 √† 100.

## Cr√©er notre propre ThreadPool

Dans les exemples pr√©cedents nous avons utilis√© le `ThreadPool` r√©el existant fourni par .NET.
Nous allons maintenant cr√©er notre propre version.

La signature de notre classe va ressembler √† celle du thread pool officiel :

```csharp
static class MyThreadPool
{
    public static void QueueUserWorkItem(Action action)
    {
        // [...]
    }
}
```

Note : `Action` et `delegate` repr√©sente des fonctions (des pointeurs de fonction).
Les `delegate` sont des pointeurs de fonction qui peuvent prendre n'importe quel forme (nombre et type de param√®tre, retour).
Le type `Action` est un type sp√©cifique de delegate (tr√®s utilis√©) qui ne prend aucun param√®tre et ne renvoie rien.

### Stockage et ex√©cution

Nous avons besoin de stocker quelque part ces actions √† effectuer, comme l'indique le nom de la m√©thode :

```csharp
static class MyThreadPool
{
    private static readonly BlockingCollection<Action> s_workItems = new();

    public static void QueueUserWorkItem(Action action)
    {
        // [...]
    }
}
```

L'int√©r√™t de la `BlockingCollection<T>` √©tant qu'elle se comporte comme une `ConcurrentQueue<T>` lorsqu'il s'agit d'ajouter des √©l√©ments, mais pour retirer un √©l√©ment elle devient bloquante : si la liste est vide l'appel sera bloquant.
Ce comportement est exactement celui souhait√© pour un thread pool : tous les threads vont tenter de prendre des choses √† ex√©cuter depuis ma file d'attente, et lorsqu'il n'y aura rien √† traiter ils attendront simplement.

Il faut d√©sormais ajouter le code pour effectuer le traitement.

Il existe deux types de thread en .NET : les background threads (arri√®re-plan) et foreground threads (premier-plan).
La seule diff√©rence entre les deux concerne le moment o√π la m√©thode d'entr√©e de votre programme se termine : est-ce que le process doit attendre que tous les threads qui travaillent encore se terminent ou doit-il les interrompre ?
Le process attendra que les threads foreground (de premier plan) se terminent et les threads background seront interrompus. Si vous avez un thread qui effectue une boucle infinie en attente de traitement, il faudra donc penser √† le configurer comme Background Thread.

```csharp
static class MyThreadPool
{
    private static readonly BlockingCollection<Action> s_workItems = new();

    public static void QueueUserWorkItem(Action action) => s_workItems.Add(action);

    static MyThreadPool()
    {
        // on lance autant de threads que le nombre de processeurs logiques
        for (int i = 0; i < Environment.ProcessorCount; i++)
        {
            // d√©marrage d'un thread en arri√®re-plan charg√© de d√©piler les t√¢ches √† effectuer
            new Thread(() => {
                while (true)
                {
                    Action workItem = s_workItems.Take();
                    workItem();
                }
             }) { IsBackground = true }.Start();
        }
    }
}
```

Relancer le code exemple en utilisant ce nouveau ThreadPool renverra exactement le m√™me r√©sultat :

```csharp
for (int i = 0; i < 1000; i++)
{
    int capturedVariable = i; // cr√©ation d'une variable locale pour capturer la valeur courante de i
    MyThreadPool.QueueUserWorkItem(delegate {
        Console.WriteLine(capturedVariable);
        Thread.Sleep(1000);
    });
}
Console.ReadLine();
```

Nous avons donc impl√©ment√© un pseudo ThreadPool qui se comporte apparement de la m√™me mani√®re que le ThreadPool .NET.

En v√©rit√© si vous examinez un peu le code du ThreadPool .NET r√©el vous verrez qu'il est en r√©alit√© beaucoup plus complexe. Toute cette complexit√© suppl√©mentaire tourne principalement autour de deux points :

1. Le rendre le plus efficache possible (allocations m√©moire et performances)
2. Avoir un nombre de threads dynamique. Il y a √©norm√©ment de code afin de d√©terminer la mani√®re dont le nombre de thread pour traiger les t√¢ches doit augmenter ou diminuer.

Un concept qu'il est n√©cessaire d'aborder maintenant concerne un d√©tail que beaucoup de d√©veloppeurs utilisent sans r√©ellement savoir la mani√®re dont cela fonctionne.

Par exemple lorsque vous d√©veloppez un site en ASP.NET Core, vous utilisez parfois le HttpContext, et vous utilisez HttpContext.Current pour savoir quel est le contexte de la requ√™te ASP.NET courante. Autre exemple lorsque vous utilisez les Principal avec les threads (Thread.Principal), avec des informations sur l'identit√© associ√©e au thread.

Toutes ces informations ambiantes semblent se r√©pandre et suivre le changement de thread lorque vous programmez une t√¢che asynchrone, ou que vous continuez un traitement apr√®s un traitement pr√©c√©dent asynchrone.

### Execution Context et Thread Local Storage

Mais il faut bien qu'un traitement soit responsable de cette fonctionnalit√©, et il se trouve que c'est g√©r√© via le concept d'Execution Context et de Thread Local Storage

:::note
Il ne faut pas confondre le Thread Local Storage avec la notion de *capture de contexte*.

Lorsque nous avions parl√© de la variable locale utilis√© pour capturer la valeur courante de `i` il s'agissait d'une fonctionnalit√© du compilateur qui va cr√©er du code pour que notre soit √™tre disponible dans un endroit du code ex√©cut√© dans un thread diff√©rent via des param√®tres masqu√©s.

L√† il est question de rendre des variables disponibles √† n'importe quel endroit de l'ex√©cution pour d'autres threads.
:::

Un exemple utilisant le thread local storage est la possibilit√© de marquer une variable statique avec l'attribut `[ThreadStatic]`, qui permet de garantir que chaque thread poss√®dera sa propre valeur de la variable (le champ est donc statique pour chaque thread).

Cet attribut permet seulement de dire que chaque thread poss√®dera sa propre valeur. Cela ne permet pas de faire "suivre" cette valeur lorsqu'un traitement s'ex√©cute sur plusieurs threads comme dans le cas des async/await.

Il existe un autre type pour cela, c'est le type `AsyncLocal<T>`.

```csharp
AsyncLocal<int> myValue = new();
for (int i = 0; i < 1000; i++)
{
    myValue.Value = i;
    ThreadPool.QueueUserWorkItem(delegate
    {
        Console.WriteLine(myValue.Value);
        Thread.Sleep(1000);
    });
}
Console.ReadLine();
```

Lorsque l'on lit ce code on peut avoir l'impression d'avoir le m√™me fonctionnement que dans notre cas plus haut o√π la variable √©tait partag√©e et allait provoquer le m√™me probl√®me. Sauf que ce code fonctionne parfaitement, gr√¢ce au contexte d'ex√©cution utlis√© par ce type `AsyncLocal<T>`.

Le r√¥le de ce contexte d'ex√©cution est de prendre tout ce qui est stock√© dans le stockage sp√©cifique d'un Thread et se charger de le propager lors de tous les appels asynchrones tels que `ThreadPool.QueueUserWorkItem` ou `new Thread` ou `await`.

Et donc, si l'on remplace le code d'ex√©cution pr√©c√©dent pour passer sur notre ThreadPool, on obtient le r√©sultat suviant :

```csharp
AsyncLocal<int> myValue = new();
for (int i = 0; i < 1000; i++)
{
    myValue.Value = i;
    MyThreadPool.QueueUserWorkItem(delegate
    {
        Console.WriteLine(myValue.Value);
        Thread.Sleep(1000);
    });
}
Console.ReadLine();
```

Uniquement des z√©ros.

Car d√©sormais nous r√©impl√©mentons nous-m√™me cette couche de bas-niveau, et nous devons donc aussi r√©impl√©menter ces fonctionnalit√©s.

C'est l'un des aspects int√©ressants lorsque l'on commence √† regarder sous le capot : l'occasion de r√©organiser notre mod√®le mental en ayant compris quel √©tait la fonction de chaque pi√®ce du puzzle.

Pour en revenir √† notre cas, plut√¥t que stocker uniquement l'action √† ex√©cuter, nous allons aussi stocker le contexte d'ex√©cution, qui sera transmis lors des √©changes entres threads.

```csharp
static class MyThreadPool
{
    // on stocke d√©sormais une instance de ExecutionContext
    private static readonly BlockingCollection<(Action, ExecutionContext?)> s_workItems = new();

    // on capture le contexte d'ex√©cution au moment de programmer l'action
    public static void QueueUserWorkItem(Action action) => s_workItems.Add((action, ExecutionContext.Capture()));

    static MyThreadPool()
    {
        for (int i = 0; i < Environment.ProcessorCount; i++)
        {
            new Thread(() => {
                while (true)
                {
                    // on r√©cup√®re le contexte d'ex√©cution
                    (Action workItem, ExecutionContext? context)  = s_workItems.Take();
                    workItem();
                }
             }) { IsBackground = true }.Start();
        }
    }
}
```

:::note
La classe `ExecutionContext` ressemble a un simple `Dictionary<,>` qui est stock√© dans la zone de stockage du thread. La classe en elle-m√™me est plus complexe, mais surtout par souci d'optimisation.
:::

L'API Capture() va permettre d'extraire les donn√©es d'ex√©cution du thread courant pour la passer √† la t√¢che invoqu√©e.

Il va donc falloir ensuite *restaurer* ce contexte d'ex√©cution pour le rendre disponible sur notre code :


```csharp
static class MyThreadPool
{
    private static readonly BlockingCollection<(Action, ExecutionContext?)> s_workItems = new();

    public static void QueueUserWorkItem(Action action) => s_workItems.Add((action, ExecutionContext.Capture()));

    static MyThreadPool()
    {
        for (int i = 0; i < Environment.ProcessorCount; i++)
        {
            new Thread(() => {
                while (true)
                {
                    (Action workItem, ExecutionContext? context)  = s_workItems.Take();

                    if (context == null)
                    {
                        // pas de contexte d'ex√©cution
                        workItem();
                    }
                    else
                    {
                        // lancement de l'action
                        ExecutionContext.Run(context, delegate { workItem(); }, null);
                    } 
                }
             }) { IsBackground = true }.Start();
        }
    }
}
```

**Disgression sur nullability et les delegates**

Ok donc nous avons un code qui commence √† prendre forme pour nous permettre de programmer des t√¢ches asynchrones qui s'ex√©cutent dans un contexte adapt√© (elles h√©ritent correctement du contexte parent).

Nous pouvons lancer ces t√¢ches et continuer √† faire notre traitement, par contre nous n'avons pas de moyen d'attendre ces t√¢ches, ou d'√™tre au courant lorsqu'elles se terminent.

C'est pour cette raison qu'il reste ce `Console.ReadLine()` qui permet au programme d'attendre la fin de l'ex√©cution avant de se terminer.

Pour pouvoir √™tre inform√© de l'ex√©cution de ces travaux il nous manque un objet repr√©sentant ce travail.

## L'objet Task

Nous allons donc impl√©menter notre propre version d'une t√¢che qui va nous permettre d'interagir avec cet asynchronisme.

Cette t√¢che sera une simple classe, contenant quelques donn√©es √† propos de notre t√¢che.

Par exemple le fait de savoir si elle est termin√©e ou non, via une propri√©t√© `IsCompleted`.

Il nous faut donc aussi des m√©thodes pour indiquer lorsque cette t√¢che s'est termin√©e, que ce soit correctement (`SetResult()`), ou avec une erreur (`SetException(Exception ex)`).

Nous souhaitons aussi sans doute pouvoir attendre que la t√¢che se termine, donc une m√©thode `Wait()` semble utile.
Mais peut √™tre pr√©f√©rons nous √™tre pr√©venus lorsque la t√¢che se termine, via un *callback* que nous pourrons renseigner sur la t√¢che apr√®s l'avoir d√©marr√©e : ce sera le r√¥le d'une m√©thode `ContinueWith(delegate)` que nous allons d√©finir.

```csharp
public class MyTask
{
    public bool IsCompleted { get; }
    public void SetResult() { }
    public void SetException(Exception exception) { }
    public void Wait() { }
    public void ContinueWith(Action action) { }
}
```

:::note
Dans le runtime .NET, cette structure est en r√©alit√© d√©coup√©e en deux classes : Task et TaskCompletionSource. L'objectif est de distinguer la partie uniquement observable (avec `IsCompleted`) de la partie modifiable, ceci afin d'√©viter que l'observateur puisse marquer la t√¢che comme termin√©e alors qu'il n'en est pas responsable.
:::

Maintenant que la "surface" de la t√¢che est d√©finie il nous faut d√©finit les informations stock√©es au sein de la t√¢che.

```csharp
public class MyTask
{
    private bool _completed;           // √©tat termin√© stock√© via SetResult(...) et SetException(...)
    private Exception? _exception;     // exception stock√©e via SetException(...)
    private Action? _continuation;     // action effectuer suite √† l'appel de ContinueWith(...)
    private ExecutionContext _context; // utile comme vu pr√©cemment pour propager le contexte local
}
```

L'impl√©mentation de IsCompleted semble trivial si elle devait simplement renvoyer _isCompleted, mais en r√©alit√© elle va √™tre plus complexe, pour une raison simple : MyTask doit √™tre implicitement **thread safe** car il sera utilis√© par des threads diff√©rents.

Pour le cas de IsCompleted, nous devons donc nous assurer que cette variable sera disponible uniquement lorsque l'√©tat *completed* sera totalement atteint.

Dans notre cas, cela consistera √† utiliser un verrou d'acc√®s exclusif autour de l'acc√®s √† la propri√©t√© :

```csharp
public class MyTask
{
    private bool _completed;

    public bool IsCompleted
    {
        get
        {
            lock (this)
            {
                return _completed;
            }
        }
    }
}
```

Cela prendra plus de sens lorsque nous allons impl√©menter la m√©thode pour "terminer" la t√¢che, ce qui revient √† impl√©menter une m√©thode partag√©e entre `SetCompleted()` et `SetException()`

```csharp
public class MyTask
{
    // [...]

    public void SetCompleted() => Complete(null);

    public void SetException(Exception exception) => Complete(exception);

    public void Complete(Exception exception)
    {
        lock (this)
        {
            // on se prot√®ge contre un appel alors que la t√¢che est d√©j√† marqu√©e comme termin√©e
            if(_completed) throw new InvalidOperationException("Already completed");

            // on stocke les √©ventuelles valeurs
            _completed = true;
            _exception = exception;

            // on s'occupe de lancer la t√¢che qui s'est inscrite...
            if (_continuation is not null)
            {  
                // ... en programmant son ex√©cution 
                MyThreadPool.QueueUserWorkItem(delegate
                {
                    if (_context is null)
                    {
                        // cas simple : pas de contexte captur√©, on invoque directement l'action
                        _continuation();
                    }
                    else
                    {
                        // cas plus complexe : on revient sur notre exemple pr√©c√©dent pour ex√©cuter l'action dans son propre contexte
                        ExecutionContext.Run(_context, (object? state) => ((Action)state!).Invoke(), _continuation);
                    }
                });
            }
        }
    }
}
```

Il nous reste deux m√©thodes √† impl√©menter, d'abord `ContinueWith(...)` qui est relativement simple :

```csharp
public class MyTask
{
    // [...]

    public void ContinueWith(Action action)
    {
        lock (this)
        {
            if (_completed)
            {
                // cas simple : si d√©j√† termin√©e on programme imm√©diatement l'action
                // note : le contexte est automatiquement captur√© par QueueUserWorkItem(...)
                MyThreadPool.QueueUserWorkItem(action);
            }
            else
            {
                // cas diff√©r√© : on stocke l'action √† ex√©cuter et on capture le contexte
                _continuation = action;
                _context = ExecutionContext.Capture();
            }
        }
    }
}
```

### Disgression #2 : l'usage de lock(this)

Il est souvent indiqu√© que `lock (this)` ne doit pas √™tre utilis√©, mais est-ce r√©ellement dangereux ici ? Serait-ce acceptable pour du code bas niveau ?

En fait cela d√©pend surtout de l'exposition de l'objet repr√©sent√© par `this`.
Dans le cas pr√©sent, c'est r√©ellement dangereux : `this` d√©signe l'instance de `MyTask`, qui est publique et partag√©e avec tous ceux qui vont interagir
avec le `ThreadPool`. Alors que votre verrou est r√©ellement un d√©tail d'impl√©mentation priv√© de votre t√¢che.

Or, le fait d'utiliser l'instance de `MyTask` permet √† n'importe quel utilisateur de votre code de cr√©er un `lock(myTask)`

Il y a en r√©alit√© deux aspects dans cette question :

1. Est-ce qu'il faut se m√©fier de l'utilisation de `lock(...)` ?
2. Pourquoi est-il d√©conseill√© d'utiliser `lock(this)` ? 

P

**t:34m39s**


## Bibliographies

- [Writing async/await from scratch in C# with Stephen Toub](https://www.youtube.com/watch?v=R-z2Hv-7nxk)
- [How Async/Await Really Works in C# - .NET Blog](https://devblogs.microsoft.com/dotnet/how-async-await-really-works/)